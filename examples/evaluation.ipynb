{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../supervised/bidirectional_attn/checkpoints/2020_07_21_16_09_09\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f0fa6f50588>>, {'<unk>': 0, '<pad>': 1, '0': 2, '2': 3, '1': 4, '3': 5, '<sep>': 6})\n",
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f104031cb70>>, {'<unk>': 0, '<pad>': 1, '0': 2, '1': 3, '3': 4, '2': 5, '|': 6, '(': 7, ')': 8, '*': 9, '<eos>': 10, '<sos>': 11, '[0-3]*': 12, '[0-3]': 13})\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import argparse\n",
    "import time\n",
    "import seq2seq\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "\n",
    "from regexDFAEquals import regex_equiv_from_raw, unprocess_regex, regex_equiv\n",
    "from seq2seq.optim import Optimizer\n",
    "from seq2seq.models import EncoderRNN, DecoderRNN,Seq2seq\n",
    "from seq2seq.loss import NLLLoss\n",
    "from seq2seq.util.checkpoint import Checkpoint\n",
    "from seq2seq.dataset import SourceField, TargetField\n",
    "from seq2seq.evaluator import Predictor\n",
    "from seq2seq.util.string_preprocess import get_set_num,pad_tensor, count_star, decode_tensor_input, decode_tensor_target\n",
    "from seq2seq.util.regex_operation import pos_membership_test, neg_membership_test, preprocess_regex, regex_equal,\\\n",
    "regex_inclusion,valid_regex, or_exception\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train_path', action='store', dest='train_path', help='path to train data')\n",
    "parser.add_argument('--test_path', action='store', dest='test_path', help='path to test data')\n",
    "parser.add_argument('--checkpoint', action='store', dest='checkpoint', help='path to checkpoint')\n",
    "opt = parser.parse_args()\n",
    "\n",
    "latest_check_point = Checkpoint.get_latest_checkpoint(opt.checkpoint)\n",
    "checkpoint = Checkpoint.load(latest_check_point)\n",
    "input_vocab = checkpoint.input_vocab\n",
    "output_vocab = checkpoint.output_vocab\n",
    "print(latest_check_point)\n",
    "print(input_vocab.stoi)\n",
    "print(output_vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2seq(\n",
      "  (encoder): EncoderRNN(\n",
      "    (input_dropout): Dropout(p=0.25, inplace=False)\n",
      "    (embedding): Embedding(7, 128)\n",
      "    (rnn): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.25, bidirectional=True)\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (input_dropout): Dropout(p=0.25, inplace=False)\n",
      "    (rnn): GRU(256, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (embedding): Embedding(14, 256)\n",
      "    (attention): Attention(\n",
      "      (linear_out): Linear(in_features=512, out_features=256, bias=True)\n",
      "    )\n",
      "    (out): Linear(in_features=256, out_features=14, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = checkpoint.model\n",
    "optimizer = checkpoint.optimizer\n",
    "weight = torch.ones(len(output_vocab))\n",
    "pad = output_vocab.stoi['<pad>']\n",
    "loss = NLLLoss(weight, pad)\n",
    "batch_size = 1 \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaemanson/project/base_model/pytorch-seq2seq/venv/lib64/python3.6/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/home/jaemanson/project/base_model/pytorch-seq2seq/venv/lib64/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/home/jaemanson/project/base_model/pytorch-seq2seq/venv/lib64/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_file = opt.train_path\n",
    "test_file = opt.test_path\n",
    "src = SourceField()\n",
    "tgt = TargetField()\n",
    "\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path=train_file, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)]\n",
    ")\n",
    "test_data = torchtext.data.TabularDataset(\n",
    "    path=test_file, format='tsv',\n",
    "    fields=[('src', src), ('tgt', tgt)]\n",
    ")\n",
    "\n",
    "src.build_vocab(train, max_size=500)\n",
    "tgt.build_vocab(train, max_size=500)\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else -1\n",
    "batch_iterator = torchtext.data.BucketIterator(\n",
    "    dataset=test_data, batch_size=1,\n",
    "    sort=False, sort_within_batch=False,sort_key=lambda x: len(x.src),\n",
    "    device=device, repeat=False, shuffle=False, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaemanson/project/base_model/pytorch-seq2seq/venv/lib64/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/jaemanson/project/base_model/pytorch-seq2seq/venv/lib64/python3.6/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations:  100 ,  0.894\n",
      "\n",
      "Iterations:  200 ,  0.888\n",
      "\n",
      "Iterations:  300 ,  0.881\n",
      "\n",
      "Iterations:  400 ,  0.891\n",
      "\n",
      "Iterations:  500 ,  0.904\n",
      "\n",
      "Iterations:  600 ,  0.904\n",
      "\n",
      "Iterations:  700 ,  0.904\n",
      "\n",
      "Iterations:  800 ,  0.913\n",
      "\n",
      "Iterations:  900 ,  0.913\n",
      "\n",
      "Iterations:  1000 ,  0.913\n",
      "\n",
      "Iterations:  1100 ,  0.915\n",
      "\n",
      "Iterations:  1200 ,  0.913\n",
      "\n",
      "Iterations:  1300 ,  0.912\n",
      "\n",
      "Iterations:  1400 ,  0.911\n",
      "\n",
      "Iterations:  1500 ,  0.912\n",
      "\n",
      "Iterations:  1600 ,  0.912\n",
      "\n",
      "Iterations:  1700 ,  0.913\n",
      "\n",
      "Iterations:  1800 ,  0.915\n",
      "\n",
      "Iterations:  1900 ,  0.914\n",
      "\n",
      "Iterations:  2000 ,  0.914\n",
      "\n",
      "Iterations:  2100 ,  0.904\n",
      "\n",
      "Iterations:  2200 ,  0.891\n",
      "\n",
      "Iterations:  2300 ,  0.881\n",
      "\n",
      "Iterations:  2400 ,  0.873\n",
      "\n",
      "Iterations:  2500 ,  0.866\n",
      "\n",
      "Iterations:  2600 ,  0.858\n",
      "\n",
      "Iterations:  2700 ,  0.849\n",
      "\n",
      "Iterations:  2800 ,  0.841\n",
      "\n",
      "Iterations:  2900 ,  0.836\n",
      "\n",
      "Iterations:  3000 ,  0.831\n",
      "\n",
      "Iterations:  3100 ,  0.824\n",
      "\n",
      "Iterations:  3200 ,  0.819\n",
      "\n",
      "Iterations:  3300 ,  0.814\n",
      "\n",
      "Iterations:  3400 ,  0.810\n",
      "\n",
      "Iterations:  3500 ,  0.806\n",
      "\n",
      "Iterations:  3600 ,  0.803\n",
      "\n",
      "Iterations:  3700 ,  0.800\n",
      "\n",
      "Iterations:  3800 ,  0.797\n",
      "\n",
      "Iterations:  3900 ,  0.792\n",
      "\n",
      "Iterations:  4000 ,  0.788\n",
      "\n",
      "Iterations:  4100 ,  0.784\n",
      "\n",
      "Iterations:  4200 ,  0.781\n",
      "\n",
      "Iterations:  4300 ,  0.776\n",
      "\n",
      "Iterations:  4400 ,  0.770\n",
      "\n",
      "Iterations:  4500 ,  0.768\n",
      "\n",
      "Iterations:  4600 ,  0.765\n",
      "\n",
      "Iterations:  4700 ,  0.762\n",
      "\n",
      "Iterations:  4800 ,  0.758\n",
      "\n",
      "Iterations:  4900 ,  0.756\n",
      "\n",
      "Iterations:  5000 ,  0.753\n",
      "\n",
      "Iterations:  5100 ,  0.751\n",
      "\n",
      "Iterations:  5200 ,  0.748\n",
      "\n",
      "Iterations:  5300 ,  0.746\n",
      "\n",
      "Iterations:  5400 ,  0.742\n",
      "\n",
      "Iterations:  5500 ,  0.738\n",
      "\n",
      "Iterations:  5600 ,  0.735\n",
      "\n",
      "Iterations:  5700 ,  0.731\n",
      "\n",
      "Iterations:  5800 ,  0.728\n",
      "\n",
      "Iterations:  5900 ,  0.726\n",
      "\n",
      "Iterations:  6000 ,  0.724\n",
      "\n",
      "Iterations:  6100 ,  0.721\n",
      "\n",
      "Iterations:  6200 ,  0.719\n",
      "\n",
      "Iterations:  6300 ,  0.717\n",
      "\n",
      "Iterations:  6400 ,  0.715\n",
      "\n",
      "Iterations:  6500 ,  0.712\n",
      "\n",
      "Iterations:  6600 ,  0.711\n",
      "\n",
      "Iterations:  6700 ,  0.709\n",
      "\n",
      "Iterations:  6800 ,  0.706\n",
      "\n",
      "Iterations:  6900 ,  0.704\n",
      "\n",
      "Iterations:  7000 ,  0.703\n",
      "\n",
      "Iterations:  7100 ,  0.701\n",
      "\n",
      "Iterations:  7200 ,  0.699\n",
      "\n",
      "Iterations:  7300 ,  0.697\n",
      "\n",
      "Iterations:  7400 ,  0.694\n",
      "\n",
      "Iterations:  7500 ,  0.692\n",
      "\n",
      "Iterations:  7600 ,  0.690\n",
      "\n",
      "Iterations:  7700 ,  0.688\n",
      "\n",
      "Iterations:  7800 ,  0.686\n",
      "\n",
      "Iterations:  7900 ,  0.684\n",
      "\n",
      "[{'cnt': 2000, 'hit': 1955, 'string_equal': 1770, 'dfa_equal': 0, 'membership_equal': 185, 'invalid_regex': 3}, {'cnt': 1998, 'hit': 1609, 'string_equal': 882, 'dfa_equal': 167, 'membership_equal': 560, 'invalid_regex': 12}, {'cnt': 1998, 'hit': 1374, 'string_equal': 619, 'dfa_equal': 205, 'membership_equal': 550, 'invalid_regex': 13}, {'cnt': 1988, 'hit': 1182, 'string_equal': 435, 'dfa_equal': 259, 'membership_equal': 488, 'invalid_regex': 16}]\n",
      "537.9387505054474\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loss.reset()\n",
    "start = time.time()\n",
    "\n",
    "match = 0\n",
    "total = 0\n",
    "num_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    with open('{}_error_analysis.txt'.format(opt.checkpoint), 'w') as fw:\n",
    "        statistics = [{'cnt':0,'hit': 0,'string_equal':0,'dfa_equal':0, 'membership_equal':0, 'invalid_regex':0} for _ in range(4)]\n",
    "        for batch in batch_iterator:\n",
    "            num_samples = num_samples + 1\n",
    "            input_variables, input_lengths  = getattr(batch, seq2seq.src_field_name)\n",
    "            target_variables = getattr(batch, seq2seq.tgt_field_name)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                softmax_list, _, other =model(input_variables, input_lengths)\n",
    "            \n",
    "            length = other['length'][0]\n",
    "            tgt_id_seq = [other['sequence'][di][0].data[0] for di in range(length)]\n",
    "            tgt_seq = [output_vocab.itos[tok] for tok in tgt_id_seq]\n",
    "            \n",
    "            # calculate NLL accuracy\n",
    "            non_padding = target_variables.view(-1)[1:].ne(pad).type(torch.LongTensor)\n",
    "            predict_var = torch.stack(tgt_id_seq)\n",
    "            target_var = target_variables.view(-1)[1:]\n",
    "\n",
    "            max_len = max(len(predict_var), len(target_var))\n",
    "            padded_predict_var = pad_tensor(predict_var, max_len, output_vocab)\n",
    "            padded_target_var = pad_tensor(target_var, max_len, output_vocab)\n",
    "            padded_non_padding = pad_tensor(non_padding, max_len, output_vocab).type(torch.bool)\n",
    "            correct = padded_predict_var.eq(padded_target_var).masked_select(padded_non_padding).sum().item()\n",
    "\n",
    "            match += correct\n",
    "            total += non_padding.sum().item()\n",
    "\n",
    "            predict_regex = ' '.join(tgt_seq[:-1])\n",
    "            target_regex = decode_tensor_target(target_variables, output_vocab)\n",
    "            target_regex, predict_regex = preprocess_regex(target_regex, predict_regex)\n",
    "                        \n",
    "            for i in range(input_variables.size(0)):\n",
    "                res = \"\"\n",
    "                for j in range(input_variables[i].size(0)):\n",
    "                    res += input_vocab.itos[input_variables[i][j]]\n",
    "                res = res.replace('<pad>', '')\n",
    "            \n",
    "            inputs = res.split('<sep>')\n",
    "            pos_input = inputs[:int(len(inputs)/2)]\n",
    "            neg_input = inputs[int(len(inputs)/2):]\n",
    "            star_cnt = count_star(target_regex)\n",
    "\n",
    "            statistics[star_cnt]['cnt'] +=1            \n",
    "            # calculate regex equivalent accuracy\n",
    "            \n",
    "            if not valid_regex(predict_regex) or not or_exception(predict_regex):\n",
    "                statistics[star_cnt]['invalid_regex'] +=1\n",
    "            else:    \n",
    "                if target_regex == predict_regex:\n",
    "                    statistics[star_cnt]['hit'] +=1\n",
    "                    statistics[star_cnt]['string_equal']+=1\n",
    "                elif regex_equal(target_regex, predict_regex):\n",
    "                    statistics[star_cnt]['hit'] +=1\n",
    "                    statistics[star_cnt]['dfa_equal'] +=1\n",
    "                elif pos_membership_test(predict_regex, pos_input) and neg_membership_test(predict_regex,neg_input):\n",
    "                    statistics[star_cnt]['hit'] +=1 \n",
    "                    statistics[star_cnt]['membership_equal'] +=1\n",
    "                else: \n",
    "                    fw.write('pos_input : ' + ' '.join(pos_input)+'\\n')\n",
    "                    fw.write('neg_input : ' + ' '.join(neg_input)+'\\n')\n",
    "                    fw.write('target_regex : ' + target_regex  +'\\n')\n",
    "                    fw.write('predict_regex : ' + predict_regex + '\\n\\n')\n",
    "            \n",
    "            if total == 0:\n",
    "                accuracy = float('nan')\n",
    "            else:\n",
    "                accuracy = match / total\n",
    "                \n",
    "            if num_samples % 100 == 0:\n",
    "                print(\"Iterations: \", num_samples, \", \" , \"{0:.3f}\".format(accuracy) + '\\n')\n",
    "            \n",
    "end = time.time()\n",
    "print(statistics)\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
